{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Por favor adicione o diretório de trabalho? C:\\1.Portfolio\\Machine_Learning_DSA_Projects\\Projeto_1_Santander_Customers\\data\\01_raw\n"
     ]
    }
   ],
   "source": [
    "#Proposito Geral\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "#Visualização\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Preprocessing\n",
    "from imblearn import pipeline as pl\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Carregando os dados de um diretório desejado.\n",
    "C:\\1.Portfolio\\Machine_Learning_DSA_Projects\\Projeto_1_Santander_Customers\\data\\01_raw\n",
    "\"\"\"\n",
    "\n",
    "path = input('Por favor adicione o diretório de trabalho?')\n",
    "for dirname, _, filename in os.walk(path, topdown = True):\n",
    "    for filename in filename:\n",
    "        if filename == 'test.csv':\n",
    "                teste = pd.read_csv(os.path.join(dirname,filename))\n",
    "        else:\n",
    "            if filename == 'train.csv':\n",
    "                treino = pd.read_csv(os.path.join(dirname,filename))\n",
    "            else:\n",
    "                print(\"Carregamento não foi possível\")\n",
    "   \n",
    "\"\"\"\n",
    "Realizando o split entre variáveis independentes e dependentes.\n",
    "\"\"\"\n",
    "X = treino.drop(['ID','TARGET'],axis=1) \n",
    "y= treino.TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(X, y,x_teste):\n",
    "    \n",
    "    \"\"\"  \n",
    "    Função de processamento dos dados para posterior \n",
    "    treinamento do Modelo de Machine Learning\n",
    "    \n",
    "      1. Balanciar Dataset\n",
    "      2. Aplicar MinMaxScaler   \n",
    "      3. Aplicar a redução de dimensionalidade - PCA\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #teste ids.\n",
    "    teste_ids = x_teste['ID']\n",
    "\n",
    "    #Balanciando o dataset\n",
    "    x,y = SMOTE().fit_resample(X,y)\n",
    "    print('Balanciamento realizado: ', sorted(Counter(y).items()))\n",
    "\n",
    "    #Normalização\n",
    "    scl = MinMaxScaler()\n",
    "    scl_x = scl.fit_transform(x)\n",
    "    print(\"Dados Normalizados\")\n",
    "\n",
    "    #Redução da Dimensionalidade\n",
    "    pca = PCA(n_components = 50)\n",
    "    x_fit = pca.fit(scl_x)\n",
    "    x_red = pca.fit_transform(scl_x)\n",
    "    print(\"Redução de Dimensionalidade concluída\")\n",
    "    print(f'Variância capturada de {round(x_fit.explained_variance_ratio_.sum()*100,2)}')\n",
    "\n",
    "    #Variáveis de Treino e Teste\n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(x_red, y, test_size=0.2, random_state=42)\n",
    "    print(\"Divisão entre dados de treino e teste concluída\")\n",
    "    \n",
    "    return X_treino, X_teste, y_treino, y_teste,teste_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanciamento realizado:  [(0, 73012), (1, 73012)]\n",
      "Dados Normalizados\n",
      "Redução de Dimensionalidade concluída\n",
      "Variância capturada de 99.28\n",
      "Divisão entre dados de treino e teste concluída\n"
     ]
    }
   ],
   "source": [
    "X_treino, X_teste, y_treino, y_teste, teste_ids = processing_data(X=X,y=y,x_teste=teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39134297,  0.05671915, -0.30212529, ..., -0.68369636,\n",
       "        -0.13942536, -0.29180089],\n",
       "       [-0.8105043 ,  0.11952488, -0.6107651 , ...,  0.01740475,\n",
       "         0.04934223, -0.02201755],\n",
       "       [-0.81050431,  0.11952489, -0.61076509, ...,  0.01740472,\n",
       "         0.04934223, -0.02201752],\n",
       "       ...,\n",
       "       [-0.68020955,  0.12218101, -0.567223  , ..., -0.09382823,\n",
       "         0.09646308, -0.0532206 ],\n",
       "       [-0.70076658,  0.12249987, -0.57400063, ..., -0.0764269 ,\n",
       "         0.0886504 , -0.04853052],\n",
       "       [-0.81139504,  0.12369352, -0.61058133, ...,  0.01792438,\n",
       "         0.04685664, -0.02281086]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Visualizando dados de treino Pre-processados.\n",
    "\"\"\"\n",
    "X_treino[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Salavando os dados processados.\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "filesname = ['X_treino.csv', 'X_teste.csv', 'y_treino.csv', 'y_teste.csv','teste_ids.csv']\n",
    "files = [X_treino, X_teste, y_treino, y_teste, teste_ids]\n",
    "\n",
    "def save_process_data(filesname, files):\n",
    "    \n",
    "    \"\"\"\n",
    "    Função para utilitária para salvar array numpy como .csv \n",
    "    \n",
    "    Parametros:\n",
    "    filesname: lista de string com o nome do arquivo ex. 'arquivo.csv'\n",
    "    files: lista de arrays numpy \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    path = input('Por favor adicione o diretório de trabalho?')\n",
    "    os.chdir(path)\n",
    "    for a,b in zip(filesname, files):\n",
    "        np.savetxt(a,b,delimiter = ',', encoding = 'utf-8')\n",
    "    return print(\"Arquivos salvos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Por favor adicione o diretório de trabalho? C:\\1.Portfolio\\Machine_Learning_DSA_Projects\\Projeto_1_Santander_Customers\\data\\02_processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos salvos\n"
     ]
    }
   ],
   "source": [
    "save_process_data(filesname=filesname, files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
